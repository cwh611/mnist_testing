{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1,2])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([[-1,2,3],\n",
    "              [3,4,5]])\n",
    "z.shape\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[[1,2,3],\n",
    "               [4,5,6]],\n",
    "              [[7,8,9],\n",
    "               [10,11,12]]])\n",
    "w.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([[7, 8, 9],\n",
    "              [10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 10, 12],\n",
       "       [13, 15, 17]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_add(z, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized version: 0.012146 seconds\n",
      "Naive version: 1.657449 seconds\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "t1 = time.time()\n",
    "print(\"Vectorized version: %f seconds\" % (t1 - t0))\n",
    "\n",
    "t2 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "t3 = time.time()\n",
    "print(\"Naive version: %f seconds\" % (t3 - t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.random((32, 10))\n",
    "b = np.random.random((10,))\n",
    "\n",
    "b = np.expand_dims(b, axis=0)\n",
    "b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.concatenate([b] * 32, axis=0)\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [4, 6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "y = np.array([1, 2])\n",
    "naive_add_matrix_and_vector(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52105226 0.87666829 0.62926254 0.28950919 0.06325177 0.56998732\n",
      " 0.92469323 0.10468054 0.79432369 0.88092596 0.61301091 0.10738974\n",
      " 0.74350137 0.20137366 0.75637048 0.90654844 0.98305312 0.40684916\n",
      " 0.43227564 0.42480658 0.88878975 0.70654758 0.03420572 0.22252645\n",
      " 0.50590084 0.4364481  0.49629987 0.00845462 0.23803342 0.53845544\n",
      " 0.367019   0.82094759]\n",
      "[0.83587135 0.78280186 0.20623463 0.69804845 0.44612921 0.43711701\n",
      " 0.66479639 0.01237058 0.12662672 0.83504204 0.15820763 0.66551139\n",
      " 0.43918729 0.28834517 0.38485647 0.34032337 0.28550246 0.84057408\n",
      " 0.39901496 0.84130446 0.80488805 0.06401842 0.99957512 0.89468941\n",
      " 0.30148168 0.07837063 0.82727172 0.09777112 0.68091752 0.50284708\n",
      " 0.09210093 0.85168429]\n",
      "8.246292216780319\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(x.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2])\n",
    "y = np.array([3, 4])\n",
    "naive_vector_dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 26.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3],\n",
    "              [3, 4, 5]])\n",
    "y = np.array([1, 2, 3])\n",
    "naive_matrix_vector_dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 26.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_matrix_vector_dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2, 3],\n",
    "              [1, 2, 3]],\n",
    "              [[1, 2, 3],\n",
    "              [1, 2, 3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.81127383e-01 6.87794538e-01 5.19075762e-01 6.97183048e-01\n",
      "  3.37500386e-01 9.93293940e-01 9.64005415e-01 9.02216669e-01\n",
      "  5.76743229e-01 6.31765495e-01 2.63099575e-01 3.18775602e-01\n",
      "  4.25042125e-01 1.05155552e-01 1.88612663e-01 5.57208423e-01\n",
      "  2.46425075e-01 7.93102755e-01 2.82057801e-01 1.15777607e-01\n",
      "  4.07900460e-01 9.24510489e-01 8.34997723e-01 9.41314813e-01\n",
      "  5.04836368e-01 8.93473260e-02 7.02373964e-01 1.82491532e-01]\n",
      " [4.57644321e-01 3.84335644e-01 7.89254991e-02 5.43397204e-01\n",
      "  8.36800730e-01 9.21423721e-01 9.69809577e-01 7.92079200e-01\n",
      "  1.37217556e-01 2.53694934e-01 6.86584181e-01 7.14011778e-01\n",
      "  9.09879825e-02 1.08822668e-01 9.54296229e-01 2.90582198e-01\n",
      "  7.92587031e-01 1.24847130e-01 7.85111302e-01 5.38405000e-01\n",
      "  2.94311103e-02 9.27633329e-01 7.42301033e-01 8.61127411e-01\n",
      "  2.60341969e-01 3.81835257e-01 2.36249244e-01 5.66380011e-01]\n",
      " [9.05112643e-01 3.09236768e-01 1.41953499e-02 8.78253379e-01\n",
      "  8.84028137e-01 9.06382083e-01 9.87489243e-01 1.69502362e-01\n",
      "  3.14802338e-01 4.46331830e-01 5.48884698e-01 3.71117819e-01\n",
      "  6.06573063e-01 5.60649440e-01 7.75483856e-01 8.82877170e-01\n",
      "  3.00000353e-01 1.88890737e-01 8.62756873e-01 3.17131518e-01\n",
      "  1.99058546e-01 1.87394345e-01 9.51948789e-01 5.68287018e-01\n",
      "  8.32791960e-01 5.31506428e-01 9.68424081e-01 3.64647005e-02]\n",
      " [1.18031243e-01 1.61529201e-03 5.51195801e-01 3.73067352e-01\n",
      "  9.58663869e-01 3.08552558e-01 8.76778699e-01 3.54731173e-01\n",
      "  2.59915539e-01 2.61738472e-02 9.47753945e-01 5.37537830e-01\n",
      "  5.36805998e-01 8.84483592e-02 1.59320848e-01 2.49055893e-02\n",
      "  7.57591503e-01 3.11900952e-01 4.16462360e-01 4.44822047e-02\n",
      "  2.25302380e-01 1.14008285e-01 1.00177052e-02 5.79828144e-02\n",
      "  2.59099546e-01 3.21726635e-01 7.87532844e-01 8.47444569e-01]\n",
      " [5.86100288e-01 4.65223442e-01 9.38873661e-01 9.70358168e-01\n",
      "  4.83432057e-01 9.94685356e-01 9.56702856e-01 7.94264200e-01\n",
      "  8.56192275e-01 3.12695061e-01 3.22813899e-01 3.31333430e-01\n",
      "  7.18294971e-01 1.85980141e-02 6.89634911e-01 1.46436909e-01\n",
      "  7.64307283e-01 1.06983563e-01 5.94650060e-01 9.49110432e-01\n",
      "  3.91725054e-01 8.20934481e-01 9.81819228e-01 1.40616031e-01\n",
      "  9.42796805e-01 3.45784941e-01 7.16571648e-01 2.62580960e-01]\n",
      " [4.46456252e-01 1.29413465e-01 6.61835837e-01 4.94000504e-02\n",
      "  9.68912958e-01 5.24709019e-01 7.43760642e-01 6.43634801e-01\n",
      "  9.93202949e-01 2.43908442e-01 3.45906131e-01 6.58317125e-01\n",
      "  6.99407744e-03 4.78318834e-01 7.35893712e-01 1.34594000e-01\n",
      "  4.02748393e-01 3.43001767e-01 4.57080399e-01 9.76680858e-01\n",
      "  2.35099591e-01 8.06425577e-01 8.33463018e-01 5.69804246e-01\n",
      "  5.87823431e-01 2.86939906e-02 3.70505375e-01 4.51529377e-02]\n",
      " [9.85680765e-01 9.50335061e-01 3.14473322e-01 9.09024091e-01\n",
      "  7.64993641e-01 8.41754433e-01 9.72393002e-01 8.61851003e-01\n",
      "  3.02333128e-01 8.26280313e-01 2.98032771e-01 9.57604370e-01\n",
      "  2.22728461e-01 1.57758173e-01 5.18341308e-01 8.29732610e-01\n",
      "  1.98062527e-01 3.34597766e-01 5.84367482e-01 2.07874109e-01\n",
      "  3.83792944e-01 8.69483832e-01 9.05772336e-01 2.92473507e-01\n",
      "  2.67009741e-01 5.00306918e-02 9.93324150e-01 8.23884693e-01]\n",
      " [4.12444310e-01 8.21708591e-01 1.75875102e-01 5.35319732e-01\n",
      "  1.73043518e-01 7.70224524e-01 9.48044013e-01 4.18987508e-01\n",
      "  6.06771970e-01 3.13295456e-01 7.54938023e-01 9.69351956e-01\n",
      "  2.41809092e-01 6.04390970e-01 8.43611311e-01 8.81082720e-01\n",
      "  4.71019746e-01 5.54026313e-01 3.95132566e-01 5.54453390e-01\n",
      "  6.33592680e-01 9.86384175e-02 4.42969233e-01 2.45010892e-01\n",
      "  7.63718877e-01 7.33164769e-01 4.35939020e-01 3.48999787e-01]\n",
      " [8.18610645e-01 7.28517632e-01 6.93569503e-01 6.39309549e-01\n",
      "  6.88071623e-01 2.72651275e-01 3.05540407e-01 7.86025799e-01\n",
      "  6.87285488e-01 1.26302814e-01 3.04101557e-01 3.03042288e-01\n",
      "  9.60922408e-01 6.22478011e-02 9.76491834e-01 5.39091211e-01\n",
      "  8.60336982e-01 8.41520284e-01 5.59402584e-02 8.84718383e-01\n",
      "  4.74597652e-01 6.10768106e-01 5.47519541e-01 3.00719937e-01\n",
      "  8.68726115e-01 2.55484454e-01 2.30573803e-01 1.52781242e-01]\n",
      " [3.05777608e-02 5.97189402e-01 2.32299712e-01 9.66758103e-01\n",
      "  8.82086968e-02 5.22322868e-01 8.37286590e-01 7.42391093e-01\n",
      "  7.98016033e-01 1.80199436e-01 5.49938624e-01 4.75375368e-01\n",
      "  3.88164142e-01 9.07384523e-01 5.73122942e-01 5.66651983e-01\n",
      "  1.48307798e-01 2.68438982e-01 4.77989155e-01 4.28390597e-01\n",
      "  1.18476216e-01 9.72451616e-01 5.64345285e-01 4.24915431e-01\n",
      "  2.53365797e-02 3.87297102e-01 1.52466332e-01 8.82847116e-01]\n",
      " [3.79437600e-01 9.02921060e-01 9.58538931e-01 1.21671281e-01\n",
      "  2.01234729e-01 6.27516062e-01 1.22727875e-01 3.30492123e-01\n",
      "  7.08469209e-01 6.36743840e-01 4.05641896e-01 2.95348668e-01\n",
      "  8.02978675e-02 4.56777037e-01 5.98649693e-01 4.59808634e-01\n",
      "  8.82232326e-01 2.36478071e-01 8.94941007e-01 3.31357061e-01\n",
      "  6.67025738e-01 3.52401226e-01 6.19225704e-01 2.63822739e-01\n",
      "  8.96873440e-01 2.46749263e-01 4.48685659e-01 5.68201959e-01]\n",
      " [6.03082165e-01 7.92131843e-01 1.71695446e-01 3.23479164e-01\n",
      "  7.96998776e-02 5.72635015e-01 1.59419155e-01 2.19008623e-01\n",
      "  1.26289527e-01 7.94844178e-01 9.94597254e-01 2.49861974e-01\n",
      "  5.51394018e-01 4.27860553e-01 9.74995416e-02 1.33622567e-01\n",
      "  8.56476493e-02 8.30743113e-01 2.51186479e-01 5.82160655e-01\n",
      "  7.93682459e-01 6.24618948e-01 8.10550241e-01 4.54725937e-01\n",
      "  9.16862300e-01 7.50202638e-01 9.14392595e-01 1.64647325e-01]\n",
      " [2.35863332e-01 6.67119593e-01 2.90170521e-02 8.17713852e-01\n",
      "  7.14117868e-02 9.53452682e-01 2.01566282e-01 2.22349320e-01\n",
      "  7.01990804e-01 8.54089258e-01 1.25410183e-01 3.97479114e-01\n",
      "  2.14815534e-01 9.44933137e-01 4.44365644e-01 6.52073758e-01\n",
      "  3.55363800e-01 1.80498551e-01 4.20191018e-01 8.39772705e-01\n",
      "  3.53963835e-01 9.71536197e-01 1.92046849e-01 8.38563358e-01\n",
      "  4.74053694e-01 9.71469615e-01 3.20160509e-01 2.32637377e-01]\n",
      " [7.10836299e-01 9.89915279e-01 3.74456703e-01 7.41290810e-02\n",
      "  4.13343336e-02 7.64600177e-01 6.84691196e-01 2.52235277e-01\n",
      "  9.00907229e-01 7.76016695e-02 5.00468267e-01 7.63630017e-01\n",
      "  6.90630115e-01 9.11950282e-01 7.24496864e-01 2.62971216e-01\n",
      "  5.84668072e-01 5.04778012e-01 9.10712253e-01 5.26199424e-03\n",
      "  9.24707666e-01 6.57048344e-01 6.44162082e-01 4.31741701e-01\n",
      "  7.86979301e-01 1.18093057e-01 8.90164198e-01 4.32730461e-01]\n",
      " [1.34499175e-01 8.93214596e-01 8.38357479e-01 5.28703437e-01\n",
      "  3.17995667e-01 9.32756811e-02 9.09707181e-01 4.64072796e-01\n",
      "  6.10924818e-01 5.79156804e-01 3.60596999e-01 7.02670414e-02\n",
      "  8.07291440e-01 2.78820869e-01 4.93419112e-01 9.64408796e-01\n",
      "  4.52976331e-01 4.23617730e-04 9.42374076e-01 6.40232540e-01\n",
      "  7.87738006e-01 4.82028147e-01 8.91727830e-02 1.75400626e-01\n",
      "  9.30214454e-01 3.70314273e-01 1.52034864e-01 6.05258846e-01]\n",
      " [4.51094590e-01 8.06969404e-02 4.70354088e-01 1.56090511e-01\n",
      "  5.84155487e-01 9.78355238e-01 5.55950588e-01 9.10010617e-01\n",
      "  3.42793740e-01 3.38510826e-01 6.66679153e-01 2.43030653e-01\n",
      "  2.51923334e-01 2.39388682e-01 1.11619989e-01 2.06835487e-01\n",
      "  4.22373646e-01 7.52454176e-01 5.50613912e-01 3.78927609e-01\n",
      "  1.73775939e-01 1.31616581e-01 2.14087617e-01 9.65022524e-01\n",
      "  1.55674359e-01 2.18215983e-01 1.92447595e-01 7.95253355e-01]\n",
      " [6.01435762e-01 5.08751088e-01 4.83747670e-01 7.52279613e-01\n",
      "  6.23032999e-01 1.45209644e-01 9.30968431e-01 7.76631510e-01\n",
      "  2.52811088e-01 5.74239987e-01 6.72228404e-01 2.82188311e-01\n",
      "  8.85946480e-01 2.37239763e-01 7.97870732e-01 1.86115329e-01\n",
      "  8.53749915e-01 8.84655601e-02 1.57866497e-01 2.48250358e-01\n",
      "  5.47443693e-01 3.64443279e-01 2.06805816e-01 7.05786467e-01\n",
      "  7.26236280e-01 5.65450819e-01 5.21431132e-01 1.13061768e-01]\n",
      " [1.72802127e-01 6.26619680e-01 1.04093747e-01 2.09551024e-02\n",
      "  8.36776813e-01 5.33134355e-01 3.00161333e-01 4.24380113e-01\n",
      "  9.34298412e-02 1.23949158e-01 9.17278253e-01 7.23482330e-01\n",
      "  5.72296664e-01 6.41782073e-01 5.17672448e-01 8.28979097e-01\n",
      "  3.22614290e-02 4.72890886e-01 2.16767472e-01 6.38918883e-01\n",
      "  6.08292430e-01 1.89748983e-01 6.81492709e-01 3.45977406e-01\n",
      "  2.35250677e-01 4.29296314e-01 6.71419463e-01 7.12880480e-01]\n",
      " [8.02485148e-01 1.13691847e-01 7.19434671e-01 2.17546823e-01\n",
      "  1.56614216e-01 6.86239297e-01 9.10339968e-01 3.18285920e-01\n",
      "  4.67468689e-01 5.93917939e-01 5.67882662e-01 6.13228493e-01\n",
      "  6.66574741e-01 6.01255211e-01 3.67552294e-01 6.08410813e-01\n",
      "  7.09533779e-01 6.76077151e-01 4.02541778e-01 4.22406671e-02\n",
      "  6.77109167e-01 8.54000809e-01 7.11711201e-01 3.20920658e-01\n",
      "  3.48467436e-01 7.89334925e-02 5.39980899e-01 1.34748535e-01]\n",
      " [2.29753540e-01 1.64278002e-01 9.64722537e-01 3.11897930e-01\n",
      "  6.40478387e-01 8.29771452e-01 4.57464511e-01 8.22683959e-01\n",
      "  6.11744188e-01 2.52891405e-01 4.86938287e-01 6.25932922e-01\n",
      "  1.27614703e-01 9.28857286e-01 7.54635401e-01 1.10272167e-01\n",
      "  6.99809269e-01 4.71330290e-01 8.78421242e-01 3.18842311e-01\n",
      "  6.10553371e-01 9.76426584e-01 2.22590743e-01 3.85044476e-01\n",
      "  8.40928078e-02 7.72603476e-01 5.05775203e-01 4.92133815e-01]\n",
      " [8.98238686e-01 5.66990587e-01 4.77337225e-01 2.30790116e-01\n",
      "  4.72957326e-01 8.99091147e-02 3.02253309e-01 9.68634955e-01\n",
      "  6.13839887e-01 4.40690776e-01 8.62399594e-01 4.61367822e-01\n",
      "  9.94834054e-01 8.15825605e-01 6.30215232e-01 1.68189915e-01\n",
      "  3.38571555e-01 6.79311154e-01 1.71292669e-01 9.06243722e-01\n",
      "  3.80203508e-01 7.21282977e-01 4.00753395e-01 1.96944651e-01\n",
      "  7.48294309e-01 3.72572506e-01 3.33802389e-01 2.43341838e-01]\n",
      " [1.37676899e-01 8.55687466e-01 9.10368459e-01 1.86813711e-03\n",
      "  5.48999709e-01 2.45313487e-01 8.44259243e-01 8.79040368e-02\n",
      "  6.69815738e-01 4.48008697e-01 7.92603730e-01 3.95866455e-01\n",
      "  6.22680360e-01 7.45533850e-01 9.90882663e-01 5.51524208e-02\n",
      "  3.57440729e-01 6.97694860e-01 7.93042766e-01 3.34823754e-01\n",
      "  3.86755237e-01 8.27944516e-01 8.20091552e-01 8.49042553e-01\n",
      "  8.22312652e-02 1.67310936e-01 9.59857044e-01 6.69109357e-01]\n",
      " [2.70713261e-01 8.58418508e-01 4.82905407e-01 7.06177851e-01\n",
      "  7.38999730e-01 3.09420113e-01 5.30014347e-01 2.63533567e-01\n",
      "  1.07954336e-01 8.80306870e-01 7.48252040e-01 3.10637437e-01\n",
      "  2.39918626e-01 9.14110410e-01 3.66999014e-01 6.68077999e-01\n",
      "  2.61151356e-01 5.31570017e-02 4.77486001e-01 2.12020484e-01\n",
      "  5.08116049e-01 9.31630898e-01 3.22268234e-01 1.03792461e-01\n",
      "  5.41529109e-01 6.21103224e-01 1.06563599e-02 6.11614258e-01]\n",
      " [7.91807224e-01 5.60320168e-01 7.56255880e-01 4.08765771e-01\n",
      "  6.51046587e-01 7.85589960e-01 6.87650110e-01 5.04287540e-01\n",
      "  3.52347004e-02 6.11291723e-01 2.30827471e-01 3.52495815e-01\n",
      "  8.11664671e-01 8.33140573e-01 8.45098833e-02 9.91013491e-01\n",
      "  9.93361780e-01 4.67144929e-01 8.70434440e-01 9.01817248e-01\n",
      "  6.86446293e-01 4.83976251e-01 1.40332487e-01 7.63395243e-01\n",
      "  5.07794129e-01 7.59870123e-01 4.66551173e-01 4.78552069e-01]\n",
      " [9.97404534e-01 6.89763849e-01 8.92267001e-01 8.29205846e-01\n",
      "  6.70680423e-02 1.72437027e-01 6.13920481e-01 9.23347519e-01\n",
      "  2.89886192e-01 8.76330605e-02 7.15032235e-01 4.88106777e-01\n",
      "  8.73558359e-01 7.16202716e-03 7.90134274e-01 7.77973222e-01\n",
      "  5.35337788e-01 4.57008638e-01 4.12154351e-01 5.52251046e-01\n",
      "  1.41660468e-01 1.66712628e-01 3.61114723e-01 1.65658886e-01\n",
      "  6.63491972e-01 8.64948154e-01 1.72252067e-01 6.58564994e-01]\n",
      " [5.72539529e-01 7.86585894e-01 9.29015045e-01 1.62455829e-01\n",
      "  8.11341419e-01 4.59588267e-01 2.78568144e-01 9.62745707e-01\n",
      "  4.68086810e-02 9.34810152e-02 9.35787486e-01 4.31780463e-01\n",
      "  7.40643130e-01 2.95088943e-01 3.40049153e-01 8.70012909e-01\n",
      "  6.68915029e-01 7.56422977e-02 3.93025992e-01 8.46374472e-01\n",
      "  1.94295081e-01 7.67771130e-01 5.52825508e-01 6.31011429e-01\n",
      "  7.84354028e-01 8.88081596e-01 3.61183066e-01 4.38730533e-01]\n",
      " [2.86811100e-01 9.18640162e-01 2.80583670e-01 7.07838679e-01\n",
      "  6.92560284e-01 6.21169520e-03 4.24464880e-01 6.71154590e-01\n",
      "  3.50847334e-01 7.48322515e-01 4.34848231e-01 2.61592549e-02\n",
      "  1.69824045e-01 1.24559826e-01 9.03926337e-01 9.02690316e-01\n",
      "  5.79970108e-01 9.42621831e-01 3.27944177e-01 3.75376948e-01\n",
      "  1.35839887e-01 7.17559706e-01 8.29525407e-01 9.54265028e-01\n",
      "  3.50042714e-01 1.94190298e-01 2.33785812e-02 6.32592666e-01]\n",
      " [8.37274809e-01 5.88220169e-01 3.68605822e-01 4.31358227e-01\n",
      "  8.52184101e-01 8.99994014e-01 8.09021180e-01 2.64265489e-01\n",
      "  7.14135491e-03 4.98503290e-01 3.91422465e-01 9.15660628e-01\n",
      "  2.13226074e-02 3.17519654e-01 3.69003865e-01 6.29173496e-01\n",
      "  1.99917276e-01 1.67232138e-02 2.91603791e-01 2.72949991e-01\n",
      "  8.94611259e-01 3.59030481e-01 4.91524340e-01 7.75078489e-01\n",
      "  5.42955803e-01 4.03266854e-01 9.69517161e-01 2.58523904e-02]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((28, 28))\n",
    "print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28* 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 6.56\n",
      "loss at batch 100: 2.24\n",
      "loss at batch 200: 2.20\n",
      "loss at batch 300: 2.09\n",
      "loss at batch 400: 2.20\n",
      "Epoch 1\n",
      "loss at batch 0: 1.89\n",
      "loss at batch 100: 1.89\n",
      "loss at batch 200: 1.82\n",
      "loss at batch 300: 1.71\n",
      "loss at batch 400: 1.81\n",
      "Epoch 2\n",
      "loss at batch 0: 1.57\n",
      "loss at batch 100: 1.59\n",
      "loss at batch 200: 1.50\n",
      "loss at batch 300: 1.43\n",
      "loss at batch 400: 1.50\n",
      "Epoch 3\n",
      "loss at batch 0: 1.32\n",
      "loss at batch 100: 1.35\n",
      "loss at batch 200: 1.24\n",
      "loss at batch 300: 1.21\n",
      "loss at batch 400: 1.27\n",
      "Epoch 4\n",
      "loss at batch 0: 1.12\n",
      "loss at batch 100: 1.17\n",
      "loss at batch 200: 1.04\n",
      "loss at batch 300: 1.05\n",
      "loss at batch 400: 1.10\n",
      "Epoch 5\n",
      "loss at batch 0: 0.98\n",
      "loss at batch 100: 1.03\n",
      "loss at batch 200: 0.90\n",
      "loss at batch 300: 0.93\n",
      "loss at batch 400: 0.98\n",
      "Epoch 6\n",
      "loss at batch 0: 0.87\n",
      "loss at batch 100: 0.93\n",
      "loss at batch 200: 0.80\n",
      "loss at batch 300: 0.84\n",
      "loss at batch 400: 0.89\n",
      "Epoch 7\n",
      "loss at batch 0: 0.79\n",
      "loss at batch 100: 0.84\n",
      "loss at batch 200: 0.72\n",
      "loss at batch 300: 0.77\n",
      "loss at batch 400: 0.82\n",
      "Epoch 8\n",
      "loss at batch 0: 0.73\n",
      "loss at batch 100: 0.77\n",
      "loss at batch 200: 0.66\n",
      "loss at batch 300: 0.71\n",
      "loss at batch 400: 0.77\n",
      "Epoch 9\n",
      "loss at batch 0: 0.68\n",
      "loss at batch 100: 0.72\n",
      "loss at batch 200: 0.61\n",
      "loss at batch 300: 0.67\n",
      "loss at batch 400: 0.73\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 (mnist_testing)",
   "language": "python",
   "name": "mnist_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
